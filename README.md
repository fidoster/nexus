# Nexus - AI Model Evaluation Platform

> **Blind evaluation platform for comparing AI model responses in educational settings**

Nexus is an educational research platform that allows students to anonymously evaluate and rank responses from multiple AI models (GPT, Claude, Gemini), enabling unbiased assessment of AI performance.

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![License](https://img.shields.io/badge/license-MIT-green)

## ğŸ¯ Features

### For Students
- ğŸ’¬ **Submit Questions**: Ask any question to multiple AI models
- ğŸ” **Anonymous Evaluation**: Responses shown as "Model A", "Model B", "Model C"
- ğŸ† **Rank Responses**: Rate each response (1st Best, 2nd Best, 3rd Best)
- ğŸ“œ **View History**: Access previous queries and evaluations
- ğŸŒ“ **Dark Mode**: Full dark/light theme support

### For Admins
- ğŸ‘¥ **User Management**: Manage student and instructor accounts
- ğŸ“Š **Comprehensive Analytics**: View detailed performance metrics
- ğŸ† **Model Performance Rankings**: See which AI models perform best
- ğŸ“¥ **Export Data**: Download evaluation data as CSV for research
- ğŸ”‘ **API Configuration**: Manage AI provider API keys
- âš™ï¸ **Platform Settings**: Configure evaluation parameters

## ğŸš€ Tech Stack

- **Frontend**: React 18 + TypeScript + Vite
- **Styling**: Tailwind CSS v3 with dark mode
- **Routing**: React Router DOM v6
- **Backend**: Supabase (PostgreSQL + Auth)
- **Deployment**: Vercel-ready

## ğŸ“š Documentation

### Getting Started
- **[Setup Instructions](docs/SETUP_INSTRUCTIONS.md)** - Complete setup guide
- **[Blind Evaluation System](docs/BLIND_EVALUATION_SYSTEM.md)** - How anonymous evaluation works

### Admin & Research
- **[Analytics Features](docs/ANALYTICS_FEATURES.md)** - Research capabilities and data export
- **[Admin Queries](database/ADMIN_QUERIES.md)** - SQL queries for analysis

### Database
- **[Database Setup](database/SUPABASE_SETUP.md)** - Initial database configuration
- **[Update Response Policy](database/UPDATE_RESPONSE_POLICY.sql)** - Required RLS policy update

## âš¡ Quick Start

### Prerequisites
- Node.js 18+ and npm
- Supabase account

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/nexus.git
   cd nexus
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Configure environment**
   ```bash
   cp .env.example .env
   # Add your Supabase credentials
   ```

4. **Setup database**
   - Follow [database/SUPABASE_SETUP.md](database/SUPABASE_SETUP.md)
   - Run SQL scripts in Supabase SQL Editor

5. **Start development server**
   ```bash
   npm run dev
   ```

6. **Open in browser**
   ```
   http://localhost:5174
   ```

## ğŸ—ï¸ Project Structure

```
nexus/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”‚   â”œâ”€â”€ ThemeToggle.tsx  # Dark mode toggle
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ contexts/            # React contexts
â”‚   â”‚   â”œâ”€â”€ AuthContext.tsx  # Authentication
â”‚   â”‚   â””â”€â”€ ThemeContext.tsx # Theme management
â”‚   â”œâ”€â”€ pages/               # Main pages
â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx    # Student dashboard
â”‚   â”‚   â”œâ”€â”€ Admin.tsx        # Admin panel with analytics
â”‚   â”‚   â”œâ”€â”€ Login.tsx        # Login page
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ lib/                 # Utilities
â”‚   â”‚   â””â”€â”€ supabase.ts      # Supabase client
â”‚   â””â”€â”€ types/               # TypeScript types
â”œâ”€â”€ database/                # Database setup files
â”‚   â”œâ”€â”€ SUPABASE_SETUP.md    # Setup instructions
â”‚   â”œâ”€â”€ ADMIN_QUERIES.md     # Analytics queries
â”‚   â””â”€â”€ *.sql                # SQL scripts
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ BLIND_EVALUATION_SYSTEM.md
â”‚   â”œâ”€â”€ SETUP_INSTRUCTIONS.md
â”‚   â””â”€â”€ ANALYTICS_FEATURES.md
â””â”€â”€ public/                  # Static assets
```

## ğŸ“ How It Works

### Blind Evaluation Process

1. **Student submits query** â†’ Saved to database
2. **AI models generate responses** â†’ Stored with actual model names (GPT, Claude, Gemini)
3. **Responses randomized** â†’ Displayed as "Model A", "Model B", "Model C"
4. **Student ranks responses** â†’ Rankings saved with actual model IDs
5. **Admin views analytics** â†’ See which model got which rank

This ensures **unbiased evaluation** while maintaining full data for research analysis.

## ğŸ“Š Analytics Dashboard

The admin analytics dashboard provides:

- **Total Evaluations**: Count of student rankings
- **Active Students**: Number of participating students
- **Model Performance**: Average rankings by model
- **Detailed Records**: Complete evaluation history
- **CSV Export**: Download data for statistical analysis

Perfect for educational research on AI model performance!

## ğŸ” User Roles

- **Student**: Submit queries, rank responses, view history
- **Instructor**: (Future) View class analytics
- **Admin**: Full access to analytics, user management, settings

## ğŸ¨ UI Features

- âœ… ChatGPT-style interface
- âœ… Dark/Light mode with smooth transitions
- âœ… Fully responsive design
- âœ… Color-coded ranking system (Gold/Cyan/Orange)
- âœ… Real-time data updates
- âœ… Accessible and keyboard-friendly

## ğŸ› ï¸ Development

### Build for production
```bash
npm run build
```

### Preview production build
```bash
npm run preview
```

## ğŸš€ Deployment

### Vercel (Recommended)
1. Push to GitHub
2. Import project in Vercel
3. Add environment variables
4. Deploy

### Other Platforms
- Netlify
- Railway
- Render

## ğŸ¤ Contributing

Contributions welcome! This is an educational research project.

## ğŸ“ License

MIT License

---

**Made with â¤ï¸ for educational research**
